{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreslaroa/DiagnosIA/blob/main/PruebaRealDiagnosIA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27ffcdbf-0474-4cee-ab05-1fea71da1747",
      "metadata": {
        "id": "27ffcdbf-0474-4cee-ab05-1fea71da1747"
      },
      "source": [
        "Este proyecto es una prueba simulada de lo que podría ser la práctica del modelo generado con un paciente real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7d125e83-adcd-4d39-ac12-29e87ce021cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d125e83-adcd-4d39-ac12-29e87ce021cf",
        "outputId": "4fd8f1c3-3601-44ea-9ed5-a9adeb56f3f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Dividimos el dataset en train y test\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ruta al archivo dentro de \"Colab Notebooks\"\n",
        "dataset_path = '/content/drive/MyDrive/Colab Notebooks/Dataset_Completo.csv'\n",
        "\n",
        "# Cargar el dataset\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Verificar\n",
        "df.head()\n",
        "\n",
        "\n",
        "# 2) Detectar automáticamente la columna de respuesta\n",
        "columna_respuesta = 'prognosis' if 'prognosis' in df.columns else df.columns[-1]\n",
        "\n",
        "# 3) Dividir en train (70 %) y test (30 %), estratificando por prognosis\n",
        "df_train, df_test = train_test_split(\n",
        "    df,\n",
        "    test_size=0.3,\n",
        "    stratify=df[columna_respuesta],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 4) A partir de ahora, usamos SOLO el conjunto de entrenamiento para el análisis de síntomas\n",
        "df = df_train.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "df2368dc-1411-4602-9144-ac92894aff29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df2368dc-1411-4602-9144-ac92894aff29",
        "outputId": "7c42e3f6-5dc4-4783-de0e-90455421ffae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del conjunto de entrenamiento: 3473 pacientes\n",
            "Tamaño del conjunto de test: 1489 pacientes\n"
          ]
        }
      ],
      "source": [
        "# Se obtienen los nuevos data frames\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df_sin_enfermedades = df.drop(columns=['prognosis'])\n",
        "todos_sintomas = df_sin_enfermedades.columns.tolist()\n",
        "\n",
        "df.columns.tolist\n",
        "le = LabelEncoder()\n",
        "le.fit(df['prognosis'])\n",
        "class_name= le.classes_\n",
        "\n",
        "x_train = df_train[todos_sintomas].astype(int).values\n",
        "y_train = df_train['prognosis'].values\n",
        "x_test = df_test[todos_sintomas].astype(int).values\n",
        "y_test = df_test['prognosis'].values\n",
        "\n",
        "\n",
        "\n",
        "# Confirmar tamaños\n",
        "print(f'Tamaño del conjunto de entrenamiento: {x_train.shape[0]} pacientes')\n",
        "print(f'Tamaño del conjunto de test: {x_test.shape[0]} pacientes')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ec904814-b427-4e57-9651-41dcf3920eab",
      "metadata": {
        "id": "ec904814-b427-4e57-9651-41dcf3920eab"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import entropy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class BayesianSequentialDiagnostic:\n",
        "    \"\"\"\n",
        "    Modelo de diagnóstico bayesiano secuencial que selecciona preguntas (síntomas)\n",
        "    de manera óptima para maximizar la información ganada en cada paso.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, X_train, y_train, symptom_names):\n",
        "        \"\"\"\n",
        "        Inicializa el modelo con datos de entrenamiento.\n",
        "\n",
        "        Args:\n",
        "            X_train (np.ndarray): Matriz de síntomas (0/1) de tamaño [n_pacientes, n_síntomas]\n",
        "            y_train (array-like): Vector de enfermedades (etiquetas) de tamaño [n_pacientes]\n",
        "            symptom_names (list of str): Lista de nombres de los síntomas en el mismo orden que las columnas de X_train\n",
        "        \"\"\"\n",
        "        self.X_train = np.asarray(X_train)\n",
        "        self.y_train = np.asarray(y_train)\n",
        "        self.symptom_names = list(symptom_names)\n",
        "        self.n_symptoms = self.X_train.shape[1]\n",
        "\n",
        "        # Etiquetas de enfermedad y mapeos\n",
        "        self.disease_labels = np.unique(self.y_train)\n",
        "        self.label_to_index = {label: i for i, label in enumerate(self.disease_labels)}\n",
        "        self.index_to_label = {i: label for label, i in self.label_to_index.items()}\n",
        "\n",
        "        # Priors P(disease)\n",
        "        self.disease_priors = {d: np.mean(self.y_train == d) for d in self.disease_labels}\n",
        "\n",
        "        # Condicionales P(symptom|disease) con suavizado de Laplace\n",
        "        self.conditional_probs = {}\n",
        "        for d in self.disease_labels:\n",
        "            cases = self.X_train[self.y_train == d]\n",
        "            self.conditional_probs[d] = (cases.sum(axis=0) + 1) / (len(cases) + 2)\n",
        "\n",
        "    def calculate_information_gain(self, symptom_idx, remaining_symptoms, current_probs):\n",
        "        \"\"\"Calcula la ganancia de información esperada al preguntar por un síntoma.\"\"\"\n",
        "        p = np.array([current_probs[d] for d in self.disease_labels])\n",
        "        current_entropy = entropy(p)\n",
        "\n",
        "        prob_pos = sum(current_probs[d] * self.conditional_probs[d][symptom_idx]\n",
        "                       for d in self.disease_labels)\n",
        "        prob_neg = 1 - prob_pos\n",
        "\n",
        "        pos_probs = {d: (self.conditional_probs[d][symptom_idx] * current_probs[d] / prob_pos\n",
        "                         if prob_pos > 0 else 0) for d in self.disease_labels}\n",
        "        neg_probs = {d: ((1 - self.conditional_probs[d][symptom_idx]) * current_probs[d] / prob_neg\n",
        "                         if prob_neg > 0 else 0) for d in self.disease_labels}\n",
        "\n",
        "        if sum(pos_probs.values()) > 0:\n",
        "            total = sum(pos_probs.values())\n",
        "            pos_probs = {d: v/total for d, v in pos_probs.items()}\n",
        "        if sum(neg_probs.values()) > 0:\n",
        "            total = sum(neg_probs.values())\n",
        "            neg_probs = {d: v/total for d, v in neg_probs.items()}\n",
        "\n",
        "        e_pos = entropy(list(pos_probs.values())) if prob_pos > 0 else 0\n",
        "        e_neg = entropy(list(neg_probs.values())) if prob_neg > 0 else 0\n",
        "        cond_entropy = prob_pos * e_pos + prob_neg * e_neg\n",
        "\n",
        "        return current_entropy - cond_entropy\n",
        "\n",
        "    def select_next_symptom(self, asked_indices, current_probs):\n",
        "        \"\"\"Selecciona el próximo síntoma basado en ganancia de información.\"\"\"\n",
        "        candidates = [i for i in range(self.n_symptoms) if i not in asked_indices]\n",
        "        if not candidates:\n",
        "            return None\n",
        "        gains = {i: self.calculate_information_gain(i, candidates, current_probs) for i in candidates}\n",
        "        return max(gains, key=gains.get)\n",
        "\n",
        "    def update_probabilities(self, current_probs, symptom_idx, symptom_value):\n",
        "        \"\"\"Actualiza las probabilidades de enfermedad usando Bayes.\"\"\"\n",
        "        updated = {}\n",
        "        for d in self.disease_labels:\n",
        "            likelihood = (self.conditional_probs[d][symptom_idx] if symptom_value == 1\n",
        "                          else 1 - self.conditional_probs[d][symptom_idx])\n",
        "            updated[d] = likelihood * current_probs[d]\n",
        "        total = sum(updated.values())\n",
        "        if total > 0:\n",
        "            updated = {d: v/total for d, v in updated.items()}\n",
        "        return updated\n",
        "\n",
        "    def diagnose(self, patient_symptoms, max_questions=20, threshold=0.9):\n",
        "        \"\"\"Diagnostica a un paciente preguntando síntomas secuencialmente y devuelve nombres.\"\"\"\n",
        "        current_probs = self.disease_priors.copy()\n",
        "        asked_names = []\n",
        "\n",
        "        for _ in range(max_questions):\n",
        "            idx = self.select_next_symptom([self.symptom_names.index(s) for s in asked_names], current_probs)\n",
        "            if idx is None:\n",
        "                break\n",
        "            name = self.symptom_names[idx]\n",
        "            val = patient_symptoms[idx]\n",
        "            current_probs = self.update_probabilities(current_probs, idx, val)\n",
        "            asked_names.append(name)\n",
        "            if current_probs[max(current_probs, key=current_probs.get)] >= threshold:\n",
        "                break\n",
        "\n",
        "        disease = max(current_probs, key=current_probs.get)\n",
        "        confidence = current_probs[disease]\n",
        "        return disease, confidence, asked_names\n",
        "\n",
        "    def evaluate(self, X_test, y_test, max_questions=20, threshold=0.9):\n",
        "        \"\"\"Evalúa rendimiento y devuelve nombres de síntomas preguntados.\"\"\"\n",
        "        results, correct, total_q = [], 0, 0\n",
        "        for x, true in zip(X_test, y_test):\n",
        "            pred, conf, asked = self.diagnose(x, max_questions, threshold)\n",
        "            correct += int(pred == true)\n",
        "            total_q += len(asked)\n",
        "            results.append({'true': true, 'pred': pred, 'confidence': conf,\n",
        "                             'asked_symptoms': asked})\n",
        "        accuracy = correct / len(y_test)\n",
        "        avg_questions = total_q / len(y_test)\n",
        "        return accuracy, avg_questions, results\n",
        "\n",
        "    def analyze_results(self, results):\n",
        "        df = pd.DataFrame(results)\n",
        "        stats = df.groupby('true').agg(accuracy=('pred', lambda x: np.mean(x == df.loc[x.index, 'true'])),\n",
        "                                        avg_questions=('asked_symptoms', lambda x: np.mean([len(i) for i in x])))\n",
        "        return stats\n",
        "\n",
        "    def plot_symptom_importance(self, top_n=20):\n",
        "        gains = [self.calculate_information_gain(i, list(range(self.n_symptoms)),\n",
        "                                               self.disease_priors) for i in range(self.n_symptoms)]\n",
        "        df = pd.DataFrame({'symptom': self.symptom_names, 'gain': gains})\n",
        "        df_top = df.sort_values('gain', ascending=False).head(top_n)\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.barh(df_top['symptom'][::-1], df_top['gain'][::-1])\n",
        "        plt.xlabel('Ganancia de información')\n",
        "        plt.title(f'Top {top_n} síntomas')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_confusion_matrix(self, results):\n",
        "        df = pd.DataFrame(results)\n",
        "        cm = pd.crosstab(df['true'], df['pred'], normalize='index')\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.imshow(cm, interpolation='nearest', aspect='auto')\n",
        "        plt.colorbar()\n",
        "        plt.xticks(range(len(cm.columns)), cm.columns, rotation=45)\n",
        "        plt.yticks(range(len(cm.index)), cm.index)\n",
        "        plt.xlabel('Predicción')\n",
        "        plt.ylabel('Verdadero')\n",
        "        plt.title('Matriz de confusión')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def compare_num_questions(self, X_test, y_test, max_questions_list=None, threshold=0.8):\n",
        "        if max_questions_list is None:\n",
        "            max_questions_list = [5, 10, 15, 20, 25, 30]\n",
        "        records = []\n",
        "        for mq in max_questions_list:\n",
        "            acc, avg_q, _ = self.evaluate(X_test, y_test, mq, threshold)\n",
        "            records.append({'max_questions': mq, 'accuracy': acc, 'avg_questions': avg_q})\n",
        "        df_res = pd.DataFrame(records)\n",
        "        fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "        ax1.plot(df_res['max_questions'], df_res['accuracy'], marker='o')\n",
        "        ax1.set_xlabel('Máximo de preguntas')\n",
        "        ax1.set_ylabel('Precisión')\n",
        "        ax2 = ax1.twinx()\n",
        "        ax2.plot(df_res['max_questions'], df_res['avg_questions'], marker='s')\n",
        "        ax2.set_ylabel('Preguntas promedio')\n",
        "        plt.title('Rendimiento vs. nº de preguntas')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        return df_res\n",
        "\n",
        "# Función interactiva corregida para usar nombres en lugar de índices\n",
        "def diagnose_interactive(model, max_questions=15, threshold=0.90):\n",
        "    \"\"\"Función para simular un diagnóstico interactivo mostrando nombres de síntomas.\"\"\"\n",
        "    current_probs = model.disease_priors.copy()\n",
        "    asked_indices = []\n",
        "    asked_names = []\n",
        "    patient_responses = {}\n",
        "\n",
        "    print(\"Sistema de diagnóstico médico interactivo\")\n",
        "    print(f\"Responda hasta {max_questions} preguntas (1=Sí, 0=No), umbral={threshold}\")\n",
        "\n",
        "    for i in range(max_questions):\n",
        "        idx = model.select_next_symptom(asked_indices, current_probs)\n",
        "        if idx is None:\n",
        "            break\n",
        "        name = model.symptom_names[idx]\n",
        "        val = None\n",
        "        while val not in (0, 1):\n",
        "            try:\n",
        "                val = int(input(f\"Pregunta {i+1}: ¿Presenta el síntoma '{name}'? (1/0): \"))\n",
        "            except ValueError:\n",
        "                print(\"Respuesta inválida. Ingrese 1 o 0.\")\n",
        "        # Guardar respuesta\n",
        "        patient_responses[name] = val\n",
        "        asked_indices.append(idx)\n",
        "        asked_names.append(name)\n",
        "        # Actualizar probabilidades\n",
        "        current_probs = model.update_probabilities(current_probs, idx, val)\n",
        "        # Mostrar top 3 provisionales\n",
        "        print(\"Diagnósticos provisionales (top 3):\")\n",
        "        for d, p in sorted(current_probs.items(), key=lambda x: x[1], reverse=True)[:3]:\n",
        "            print(f\"- {d}: {p:.2f}\")\n",
        "        # Verificar umbral\n",
        "        if current_probs[max(current_probs, key=current_probs.get)] >= threshold:\n",
        "            break\n",
        "\n",
        "    # Resultado final\n",
        "    disease = max(current_probs, key=current_probs.get)\n",
        "    confidence = current_probs[disease]\n",
        "    print(\"\" + \"=\"*50)\n",
        "    print(f\"Diagnóstico final: {disease}\")\n",
        "    print(f\"Confianza: {confidence:.4f}\")\n",
        "    print(f\"Síntomas preguntados: {asked_names}\")\n",
        "    print(\"=\"*50)\n",
        "    return disease, confidence, asked_names, patient_responses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ae6131c-5718-412b-a7a8-58202dea9aa5",
      "metadata": {
        "id": "5ae6131c-5718-412b-a7a8-58202dea9aa5"
      },
      "source": [
        "Construimos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e950c5b5-37f9-4ab3-942e-dff1271107fc",
      "metadata": {
        "id": "e950c5b5-37f9-4ab3-942e-dff1271107fc"
      },
      "outputs": [],
      "source": [
        "# 2. Inicializar y entrenar el modelo\n",
        "symptom_names = df_train.drop(columna_respuesta, axis=1).columns.tolist()\n",
        "model = BayesianSequentialDiagnostic(x_train, y_train, symptom_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2991d2e1-bde3-466b-b766-24a3c88dfbc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "2991d2e1-bde3-466b-b766-24a3c88dfbc7",
        "outputId": "5cd0622c-5187-4b83-cb95-90f06276a8f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sistema de diagnóstico médico interactivo\n",
            "Responda hasta 15 preguntas (1=Sí, 0=No), umbral=0.9\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-15-1321054663.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Uso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdiagnose_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-13-3528846155.py\u001b[0m in \u001b[0;36mdiagnose_interactive\u001b[0;34m(model, max_questions, threshold)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Pregunta {i+1}: ¿Presenta el síntoma '{name}'? (1/0): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Respuesta inválida. Ingrese 1 o 0.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# Uso\n",
        "diagnose_interactive(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "382951f9-cfa5-4400-8bef-28579f7127cf",
      "metadata": {
        "id": "382951f9-cfa5-4400-8bef-28579f7127cf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (TFG)",
      "language": "python",
      "name": "tfg_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}